{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import re \n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file containing the HE stain results\n",
    "csv_file_path = \"IPH_HE_results.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_he_results = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Extract the StudyNumber from the case_id using regular expressions\n",
    "df_he_results[\"SNR\"] = [re.search(\"^[(AE)(0-9)]*\", i).group(0) for i in df_he_results[\"case_id\"]]\n",
    "\n",
    "# Display the DataFrame\n",
    "df_he_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the secondary stain results from the CSV file\n",
    "# Uncomment the desired file to read\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_EVG_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_FIBRIN_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_SMA_results.csv\")\n",
    "df_sec_stain_results = pd.read_csv(\"IPH_GLYCC_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_SR_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_CD68_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_CD34_results.csv\")\n",
    "# df_sec_stain_results = pd.read_csv(\"IPH_CD66b_results.csv\")\n",
    "\n",
    "# Extract the StudyNumber from the case_id using regular expressions\n",
    "df_sec_stain_results[\"SNR\"] = [re.search(\"^[(AE)(0-9)]*\", i).group(0) for i in df_sec_stain_results[\"case_id\"]]\n",
    "\n",
    "# Display the DataFrame\n",
    "df_sec_stain_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the intersection of StudyNumber values between the two DataFrames\n",
    "# This will help us identify common samples between the HE results and the secondary stain results\n",
    "intersection = set(df_he_results['SNR']) & set(df_sec_stain_results['SNR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the HE results DataFrame to include only the common StudyNumber values\n",
    "df_he_results = df_he_results[df_he_results['SNR'].isin(list(intersection))]\n",
    "\n",
    "# Filter the secondary stain results DataFrame to include only the common StudyNumber values\n",
    "df_sec_stain_results = df_sec_stain_results[df_sec_stain_results['SNR'].isin(list(intersection))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the HE results DataFrame and the secondary stain results DataFrame on the 'SNR' column\n",
    "# The 'suffixes' parameter is used to differentiate columns from the two DataFrames\n",
    "df_combined = df_he_results.merge(df_sec_stain_results, how='inner', on='SNR', suffixes=[\"_HE\", \"_STAIN\"])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the value counts of the 'gt_HE' column in the combined DataFrame\n",
    "# This will show the distribution of the ground truth labels for HE stain\n",
    "df_combined[\"gt_HE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ground truth labels for HE stain to binary format\n",
    "# 'no' is converted to 0 and 'yes' is converted to 1\n",
    "y_true = df_combined[\"gt_HE\"].replace({'no': 0, 'yes': 1}).astype(int)\n",
    "\n",
    "# Extract the predicted probabilities for the secondary stain\n",
    "prob_STAIN = df_combined[\"prob_STAIN\"]\n",
    "\n",
    "# Extract the predicted probabilities for the HE stain\n",
    "prob_HE = df_combined[\"prob_HE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine probabilities into a feature matrix for the ensemble\n",
    "# This matrix will be used as input for the ensemble model\n",
    "X_ensemble = np.column_stack((prob_STAIN, prob_HE))\n",
    "\n",
    "# Display the feature matrix\n",
    "X_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-fold cross-validation with 10 splits, shuffling, and a fixed random state for reproducibility\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each fold\n",
    "auc_scores = []  # Area Under the ROC Curve scores\n",
    "accuracy_scores = []  # Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mean false positive rate (FPR) for ROC curve interpolation\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Initialize a list to store true positive rates (TPRs) for each fold\n",
    "tprs = []\n",
    "\n",
    "# Generate a mean recall for Precision-Recall curve interpolation\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "# Initialize a list to store precision values for each fold\n",
    "precisions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(X_ensemble):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X_ensemble[train_index], X_ensemble[test_index]\n",
    "    y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "    \n",
    "    # Print the size of the training and testing sets\n",
    "    print(f\"train set size: {len(X_train)}\")\n",
    "    print(f\"test set size: {len(X_test)}\")\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    ensemble_model = LogisticRegression()\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    test_probs = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluate the model\n",
    "    auc_s = roc_auc_score(y_test, test_probs)\n",
    "    accuracy = accuracy_score(y_test, (test_probs > 0.5).astype(int))\n",
    "    \n",
    "    # Append the AUC and accuracy scores to their respective lists\n",
    "    auc_scores.append(auc_s)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0) and ends at (1, 1)\n",
    "    fpr = np.insert(fpr, 0, 0.0)\n",
    "    tpr = np.insert(tpr, 0, 0.0)\n",
    "    fpr = np.append(fpr, 1.0)\n",
    "    tpr = np.append(tpr, 1.0)\n",
    "    \n",
    "    # Interpolate the true positive rates\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    \n",
    "    # Compute Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, test_probs)\n",
    "    \n",
    "    # Interpolate the precision values\n",
    "    precisions.append(np.interp(mean_recall, recall[::-1], precision[::-1]))\n",
    "\n",
    "# Average results across folds\n",
    "print(\"Average AUC:\", np.mean(auc_scores), \" --  Stdev: \", np.std(auc_scores))\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores), \" --  Stdev: \", np.std(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean ROC and PR curves\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_precision = np.mean(precisions, axis=0)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mean_fpr, mean_tpr, color=\"blue\", label=f\"Mean ROC (AUC = {np.mean(auc_scores):.2f} Â± {np.std(auc_scores):.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Mean ROC Curve (10-Fold CV)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlim(0, 1)  # Ensure x-axis goes from 0 to 1\n",
    "plt.ylim(0, 1)  # Ensure y-axis goes from 0 to 1\n",
    "plt.grid()\n",
    "\n",
    "# Remove top and right borders\n",
    "ax = plt.gca()  # Get current axis\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mean_recall, mean_precision, color=\"green\", label=f\"Mean PR Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Mean Precision-Recall Curve (10-Fold CV)\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlim(0, 1)  # Ensure x-axis goes from 0 to 1\n",
    "plt.ylim(0, 1)  # Ensure y-axis goes from 0 to 1\n",
    "plt.grid()\n",
    "\n",
    "# Remove top and right borders\n",
    "ax = plt.gca()  # Get current axis\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## Combined Version of the Code\n",
    "\n",
    "In this section, we combine the HE stain results with secondary stain results based on common SNR values. We then perform k-fold cross-validation to evaluate the performance of the ensemble model using logistic regression. The results are visualized using ROC and Precision-Recall curves.\n",
    "\n",
    "### Steps:\n",
    "1. **Load Libraries and Data**: Import necessary libraries and read the CSV files containing HE and secondary stain results.\n",
    "2. **Data Preprocessing**: Extract SNR values from the `case_id` column using regular expressions and find the intersection of SNR values between the two datasets.\n",
    "3. **Data Filtering**: Filter the datasets to include only the common SNR values and merge them on the `SNR` column.\n",
    "4. **Feature Extraction**: Extract ground truth labels and predicted probabilities for HE and secondary stains.\n",
    "5. **Ensemble Model**: Combine the probabilities into a feature matrix and perform k-fold cross-validation using logistic regression.\n",
    "6. **Evaluation**: Calculate evaluation metrics such as AUC, accuracy, and F1 score for each fold. Compute mean ROC and Precision-Recall curves.\n",
    "7. **Visualization**: Plot the mean ROC and Precision-Recall curves for each stain combination and highlight the best-performing combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store stain combinations and their corresponding CSV file paths\n",
    "stain_combos = {\n",
    "    'HE+EVG': \"IPH_EVG_results.csv\",\n",
    "    'HE+CD66b': \"IPH_CD66b_results.csv\",\n",
    "    'HE+CD34': \"IPH_CD34_results.csv\",\n",
    "    'HE+CD68': \"IPH_CD68_results.csv\",\n",
    "    'HE+SMA': \"IPH_SMA_results.csv\",\n",
    "    'HE+GLYCC': \"IPH_GLYCC_results.csv\",\n",
    "    'HE+FIBRIN': \"IPH_FIBRIN_results.csv\",\n",
    "    'HE+SR': \"IPH_SR_sb.csv\"\n",
    "    # Add more combinations here\n",
    "}\n",
    "\n",
    "# Note: Ensure that the CSV files are available in the same directory or provide the correct path.\n",
    "# This dictionary can be expanded with additional stain combinations as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stains_data_combo(stain_path, printing=False):\n",
    "    \"\"\"\n",
    "    Function to read and combine HE results with secondary stain results based on common SNR values.\n",
    "\n",
    "    Parameters:\n",
    "    stain_path (str): Path to the CSV file containing secondary stain results.\n",
    "    printing (bool): If True, prints the total number of samples and IPH splits.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame with HE and secondary stain results.\n",
    "    \"\"\"\n",
    "    # Read the HE results CSV file\n",
    "    df_he_results = pd.read_csv(\"IPH_HE_sb.csv\")\n",
    "    # Extract the SNR from the case_id using regular expressions\n",
    "    df_he_results[\"SNR\"] = [re.search(\"^[(AE)(0-9)]*\", i).group(0) for i in df_he_results[\"case_id\"]]\n",
    "\n",
    "    # Read the secondary stain results CSV file\n",
    "    df_sec_stain_results = pd.read_csv(stain_path)\n",
    "    # Extract the SNR from the case_id using regular expressions\n",
    "    df_sec_stain_results[\"SNR\"] = [re.search(\"^[(AE)(0-9)]*\", i).group(0) for i in df_sec_stain_results[\"case_id\"]]\n",
    "\n",
    "    # Find the intersection of SNR values between the two DataFrames\n",
    "    intersection = set(df_he_results['SNR']) & set(df_sec_stain_results['SNR'])\n",
    "\n",
    "    # Filter the DataFrames to include only the common SNR values\n",
    "    df_he_results = df_he_results[df_he_results['SNR'].isin(list(intersection))]\n",
    "    df_sec_stain_results = df_sec_stain_results[df_sec_stain_results['SNR'].isin(list(intersection))]\n",
    "\n",
    "    # Merge the HE results DataFrame and the secondary stain results DataFrame on the 'SNR' column\n",
    "    df_combined = df_he_results.merge(df_sec_stain_results, how='inner', on='SNR', suffixes=[\"_HE\", \"_STAIN\"])\n",
    "\n",
    "    # Print the total number of samples and IPH splits if printing is True\n",
    "    if printing:\n",
    "        print(f\"\\tTotal amount of samples: {len(df_combined)}\")\n",
    "        print(f\"\\tIPH splits: {df_combined['gt_HE'].value_counts()}\")\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update matplotlib parameters for better readability\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Initialize figures for ROC and Precision-Recall curves\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 8))\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Variables to store the best-performing combination across all combinations\n",
    "best_auc = 0\n",
    "best_auc_combo = \"\"\n",
    "best_ap = 0\n",
    "best_ap_combo = \"\"\n",
    "\n",
    "# Define colorblind-friendly palette (CUD palette)\n",
    "colorblind_palette = ['#CC79A7', '#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#FE88B1', '#000000']\n",
    "color_cycle = itertools.cycle(colorblind_palette)\n",
    "\n",
    "# Dictionary to store the assigned colors for each stain combo\n",
    "color_map_auc = {}\n",
    "color_map_ap = {}\n",
    "\n",
    "# First pass to determine the best-performing stain combinations\n",
    "for stain_combo, folder_path in stain_combos.items():\n",
    "    print(\"\\033[4m\" + stain_combo)\n",
    "    print(\"\\033[0m\")\n",
    "    combined_data = get_stains_data_combo(folder_path, printing=True)\n",
    "\n",
    "    y_true = combined_data[\"gt_HE\"].replace({'no': 0, 'yes': 1}).astype(int)\n",
    "    prob_STAIN = combined_data[\"prob_STAIN\"]\n",
    "    prob_HE = combined_data[\"prob_HE\"]\n",
    "\n",
    "    X_ensemble = np.column_stack((prob_STAIN, prob_HE))\n",
    "\n",
    "    # k-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    aps = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(X_ensemble):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test = X_ensemble[train_index], X_ensemble[test_index]\n",
    "        y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "        if i == 0:\n",
    "            print(f\"\\ttrain set size: {len(X_train)}\")\n",
    "            print(f\"\\ttest set size: {len(X_test)}\")\n",
    "            i += 1\n",
    "        # Train the logistic regression model\n",
    "        ensemble_model = LogisticRegression()\n",
    "        ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on the test set\n",
    "        test_probs = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, (test_probs > 0.5).astype(int))\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores.append(roc_auc)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "\n",
    "        # Compute Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, test_probs)\n",
    "        ap = average_precision_score(y_test, test_probs)\n",
    "        aps.append(ap)\n",
    "        interp_precision = np.interp(mean_recall, recall[::-1], precision[::-1])\n",
    "        precisions.append(interp_precision)\n",
    "\n",
    "        # Calculate F1 score for this fold\n",
    "        fold_f1 = f1_score(y_test, (test_probs > 0.5).astype(int))\n",
    "        f1_scores.append(fold_f1)\n",
    "\n",
    "    # Calculate mean values for this stain combo\n",
    "    if tprs:\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        if mean_auc > best_auc:  # Update the best-performing ROC curve\n",
    "            best_auc = mean_auc\n",
    "            best_auc_combo = stain_combo\n",
    "\n",
    "    if precisions:\n",
    "        mean_precision = np.mean(precisions, axis=0)\n",
    "        mean_ap = np.mean(aps)\n",
    "        if mean_ap > best_ap:  # Update the best-performing Precision-Recall curve\n",
    "            best_ap = mean_ap\n",
    "            best_ap_combo = stain_combo\n",
    "            \n",
    "    # Average results across folds\n",
    "    print(\"\\tAverage AUC:\", np.mean(auc_scores), \" --  Stdev: \", np.std(auc_scores))\n",
    "    print(\"\\tAverage F1 Score:\", np.mean(f1_scores), \" --  Stdev: \", np.std(f1_scores))\n",
    "    print(\"\\tAverage Accuracy:\", np.mean(accuracy_scores), \" --  Stdev: \", np.std(accuracy_scores))\n",
    "\n",
    "# Assign colors for each stain combo\n",
    "for stain_combo in stain_combos.keys():\n",
    "    color = next(color_cycle)\n",
    "    color_map_auc[stain_combo] = color\n",
    "    color_map_ap[stain_combo] = color\n",
    "\n",
    "# Second pass to plot and emphasize only the best curve\n",
    "for stain_combo, folder_path in stain_combos.items():\n",
    "    combined_data = get_stains_data_combo(folder_path)\n",
    "\n",
    "    y_true = combined_data[\"gt_HE\"].replace({'no': 0, 'yes': 1}).astype(int)\n",
    "    prob_STAIN = combined_data[\"prob_STAIN\"]\n",
    "    prob_HE = combined_data[\"prob_HE\"]\n",
    "\n",
    "    X_ensemble = np.column_stack((prob_STAIN, prob_HE))\n",
    "\n",
    "    # k-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    aps = []\n",
    "    \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_ensemble):\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test = X_ensemble[train_index], X_ensemble[test_index]\n",
    "        y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "        # Train the logistic regression model\n",
    "        ensemble_model = LogisticRegression()\n",
    "        ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict probabilities on the test set\n",
    "        test_probs = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, (test_probs > 0.5).astype(int))\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "        # ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, test_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores.append(roc_auc)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "\n",
    "        # Compute Precision-Recall curve\n",
    "        precision, recall, _ = precision_recall_curve(y_test, test_probs)\n",
    "        ap = average_precision_score(y_test, test_probs)\n",
    "        aps.append(ap)\n",
    "        interp_precision = np.interp(mean_recall, recall[::-1], precision[::-1])\n",
    "        precisions.append(interp_precision)\n",
    "    \n",
    "    # Finalize and plot ROC Curve\n",
    "    if tprs:\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        color = color_map_auc[stain_combo]  # Use the assigned color\n",
    "        line_width = 2  # Emphasize only the best-performing ROC curve\n",
    "        ax1.plot(mean_fpr, mean_tpr, lw=line_width, color=color, label=f'{stain_combo}')\n",
    "\n",
    "    # Finalize and plot Precision-Recall Curve\n",
    "    if precisions:\n",
    "        mean_precision = np.mean(precisions, axis=0)\n",
    "        mean_ap = np.mean(aps)\n",
    "        color = color_map_ap[stain_combo]  # Use the assigned color\n",
    "        line_width = 2  # Emphasize only the best-performing PR curve\n",
    "        ax2.plot(mean_recall, mean_precision, lw=line_width, color=color, label=f'{stain_combo}')\n",
    " \n",
    "# Finalizing merged ROC Curve\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--', lw=3, color='gray', alpha=.8)\n",
    "ax1.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "ax1.xaxis.label.set_size(24)\n",
    "ax1.yaxis.label.set_size(24)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "# Hide the right and top spines\n",
    "ax1.spines[['right', 'top']].set_visible(False)\n",
    "roc_save_path = './OUT_PLOTS/merged_per_2stain_joint_ROC_Curves_color_blind.pdf'\n",
    "fig1.savefig(roc_save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Finalizing merged Precision-Recall Curve\n",
    "ax2.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel='Recall', ylabel='Precision')\n",
    "ax2.xaxis.label.set_size(24)\n",
    "ax2.yaxis.label.set_size(24)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax2.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=18)  # Move legend to the right\n",
    "# Hide the right and top spines\n",
    "ax2.spines[['right', 'top']].set_visible(False)\n",
    "pr_save_path = './OUT_PLOTS/merged_per_2stain_joint_PR_Curves_color_blind.pdf'\n",
    "fig2.savefig(pr_save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpeters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
