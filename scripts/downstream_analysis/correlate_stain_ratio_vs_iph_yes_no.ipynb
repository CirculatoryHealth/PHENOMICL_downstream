{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import pyreadr\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if the output directory exists, if not, create it\n",
    "output_dir = \"./OUT/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the input file path with the IPH results\n",
    "input_file = \"./HE_samples_IPH.csv\"\n",
    "\n",
    "# Check if the input file exists\n",
    "if os.path.exists(input_file):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df_iph = pd.read_csv(input_file)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"The file {input_file} does not exist.\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_iph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the SNR (StudyNumber) from the 'case_id' column using regular expressions\n",
    "# The regular expression searches for patterns starting with 'A', 'E', or digits (0-9)\n",
    "df_iph[\"SNR\"] = [re.search(r\"^[AE0-9]*\", case_id).group(0) for case_id in df_iph[\"case_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the preprocessed <stain> CellProfiler data exists\n",
    "if os.path.exists(\"./OUT/<STAIN>_CellProfiler.csv\"):\n",
    "    # If the file exists, read it into a DataFrame\n",
    "    df_stain = pd.read_csv(\"./OUT/<STAIN>_CellProfiler.csv\")\n",
    "else:\n",
    "    # If the file does not exist, read the raw data from a specified ExpressScan SlideToolkit output file\n",
    "    # Note: Replace 'your_file_path.gct' with the actual file path\n",
    "    df_stain = pd.read_csv(\"your_file_path.gct\", sep=\"\\t\")\n",
    "\n",
    "# Display the DataFrame\n",
    "df_stain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if the preprocessed CellProfiler data exists\n",
    "output_file = \"./OUT/<STAIN>_CellProfiler.csv\"\n",
    "if not os.path.exists(output_file):\n",
    "    # Create an empty DataFrame to store the combined data\n",
    "    df_stain_together = pd.DataFrame({\"Stain\": [],\n",
    "                                      \"SNR\": [],\n",
    "                                      \"<STAIN>_area\": [],\n",
    "                                      \"<STAIN>_count\": [],\n",
    "                                      \"TISSUE\": []})\n",
    "\n",
    "    # Iterate over each row in the stain DataFrame\n",
    "    for index, row in df_stain.iterrows():\n",
    "        # Extract the SNR and stain information using regular expressions\n",
    "        row_SNR = re.search(r\"^[AE0-9]*\", row[\"NAME\"]).group(0)\n",
    "        row_STAIN = row[\"Metadata_STAIN\"]\n",
    "        row_<STAIN>_area = row[\"AreaOccupied_AreaOccupied_<STAIN>\"]\n",
    "        row_<STAIN>_count = row[\"Count_<STAIN>\"]\n",
    "        row_TISSUE = row[\"AreaOccupied_AreaOccupied_Tissue\"]\n",
    "\n",
    "        # Check if the SNR already exists in the combined DataFrame\n",
    "        if row_SNR in df_stain_together['SNR'].values:\n",
    "            # If it exists, update the existing row by adding the new values\n",
    "            df_stain_together.loc[df_stain_together['SNR'] == row_SNR, '<STAIN>_area'] += row_<STAIN>_area\n",
    "            df_stain_together.loc[df_stain_together['SNR'] == row_SNR, '<STAIN>_count'] += row_<STAIN>_count\n",
    "            df_stain_together.loc[df_stain_together['SNR'] == row_SNR, 'TISSUE'] += row_TISSUE\n",
    "        else:\n",
    "            # If it does not exist, add a new row to the combined DataFrame\n",
    "            df_stain_together = pd.concat([df_stain_together, pd.DataFrame({\"Stain\": [row_STAIN],\n",
    "                                                                            \"SNR\": [row_SNR],\n",
    "                                                                            \"<STAIN>_area\": [row_<STAIN>_area],\n",
    "                                                                            \"<STAIN>_count\": [row_<STAIN>_count],\n",
    "                                                                            \"TISSUE\": [row_TISSUE]})])\n",
    "\n",
    "    # Calculate the ratios of <STAIN>_area and <STAIN>_count to TISSUE\n",
    "    df_stain_together[\"<STAIN>_area/TISSUE\"] = df_stain_together[\"<STAIN>_area\"] / df_stain_together[\"TISSUE\"]\n",
    "    df_stain_together[\"<STAIN>_count/TISSUE\"] = df_stain_together[\"<STAIN>_count\"] / df_stain_together[\"TISSUE\"]\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    df_stain_together.to_csv(output_file, index=False)\n",
    "\n",
    "    # Display the combined DataFrame\n",
    "    df_stain_together\n",
    "else:\n",
    "    # If the preprocessed file exists, read it into a DataFrame\n",
    "    df_stain_together = pd.read_csv(output_file)\n",
    "    df_stain_together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the intersection of SNR values between the two DataFrames\n",
    "# This will help in identifying common SNR values present in both datasets\n",
    "intersection = set(df_stain_together['SNR']) & set(df_iph['SNR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'df_stain_together' DataFrame to include only rows with 'SNR' values present in the intersection set\n",
    "df_stain_together = df_stain_together[df_stain_together['SNR'].isin(list(intersection))]\n",
    "\n",
    "# Filter the 'df_iph' DataFrame to include only rows with 'SNR' values present in the intersection set\n",
    "df_iph = df_iph[df_iph['SNR'].isin(list(intersection))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'SNR' column to create a combined DataFrame\n",
    "# This will include only the rows with matching 'SNR' values in both DataFrames\n",
    "df_combined = df_iph.merge(df_stain_together, how='inner', on='SNR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of <STAIN>_count to TISSUE using log2 transformation\n",
    "# This helps in normalizing the data and handling cases where TISSUE is zero\n",
    "df_combined[\"<STAIN>_count/TISSUE\"] = np.where(\n",
    "    df_combined[\"TISSUE\"] != 0,  # Check if TISSUE is not zero to avoid division by zero\n",
    "    np.log2(df_combined['<STAIN>_count'] + 1) / np.log2(df_combined['TISSUE'] + 1),  # Apply log2 transformation and calculate the ratio\n",
    "    np.nan  # Substitute NaN for cases where TISSUE is zero\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be used for analysis\n",
    "columns = [\"<STAIN>_area/TISSUE\", '<STAIN>_count/TISSUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each column specified for analysis\n",
    "for column in columns:\n",
    "    # Separate the data into two groups based on the 'IPH' column\n",
    "    mean_yes_coord = df_combined[df_combined['IPH'] == True][column].tolist()\n",
    "    mean_no_coord = df_combined[df_combined['IPH'] == False][column].tolist()\n",
    "\n",
    "    # Create a new plot\n",
    "    ax = plt.axes()\n",
    "    box = ax.boxplot([mean_no_coord, mean_yes_coord], positions=np.linspace(0, 1, 2), widths=0.5)\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.ylabel(column)\n",
    "    plt.xlabel('IPH Yes/No')\n",
    "    plt.title(f'{column} - Grouped by IPH prediction')\n",
    "    plt.xticks([0.0, 1.0], ['No', 'Yes'])\n",
    "\n",
    "    # Get the y-axis limits\n",
    "    bottom, top = ax.get_ylim()\n",
    "    y_range = top - bottom\n",
    "\n",
    "    # Calculate significance between the two groups using Mann-Whitney U test\n",
    "    stat, p_value = mannwhitneyu(mean_no_coord, mean_yes_coord, alternative='two-sided')\n",
    "    \n",
    "    # Calculate Z-score\n",
    "    n1 = len(mean_no_coord)\n",
    "    n2 = len(mean_yes_coord)\n",
    "    mean_U = n1 * n2 / 2\n",
    "    std_U = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    z = (stat - mean_U) / std_U\n",
    "\n",
    "    # Calculate effect size r\n",
    "    N = n1 + n2\n",
    "    r = z / np.sqrt(N)\n",
    "\n",
    "    # Print statistical results\n",
    "    print(f\"U-statistic: {stat}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    print(f\"Effect size r: {r}\")\n",
    "    print(f'Mean IPH yes: {np.mean(mean_yes_coord)} - Stdev: {np.std(mean_yes_coord)}')\n",
    "    print(f'Mean IPH no: {np.mean(mean_no_coord)} - Stdev: {np.std(mean_no_coord)}')\n",
    "\n",
    "    # Plot significance bars if p-value is below threshold\n",
    "    if p_value < 0.05:  # Adjust significance level as needed\n",
    "        x1 = box['boxes'][0].get_xdata()[0] + 0.25\n",
    "        x2 = box['boxes'][1].get_xdata()[0] + 0.25\n",
    "        bar_height = top + (y_range * 0.07)\n",
    "        bar_tips = bar_height - (y_range * 0.02)\n",
    "        plt.plot([x1, x1, x2, x2], [bar_tips, bar_height, bar_height, bar_tips], lw=1, c='k')\n",
    "\n",
    "        # Determine significance symbol\n",
    "        if p_value < 0.001:\n",
    "            sig_symbol = '<0.001'\n",
    "        elif p_value < 0.01:\n",
    "            sig_symbol = '<0.01'\n",
    "        elif p_value < 0.05:\n",
    "            sig_symbol = '<0.05'\n",
    "        else:\n",
    "            sig_symbol = '---'\n",
    "        \n",
    "        # Add significance text to the plot\n",
    "        text_height = bar_height + (y_range * 0.01)\n",
    "        txt = plt.text((x1 + x2) * 0.5, text_height, sig_symbol, ha='center', va='bottom', c='k')\n",
    "        txt.set_fontsize(7)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpeters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
